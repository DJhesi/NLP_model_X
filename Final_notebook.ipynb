{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project is aimed at building and evaluating machine learning models for sentiment analysis on Twitter data. Sentiment analysis involves classifying text data into different sentiment categories such as positive, negative, or neutral. In this project, we collect and preprocess Twitter data, including cleaning the text, removing noise, and transforming it into a format suitable for machine learning algorithms.\n",
    "\n",
    "Once the data preprocessing is complete, we train several machine learning models on the preprocessed data to predict the sentiment of tweets. Some of the models considered in this project include Naive Bayes, Logistic Regression, Random Forest, AdaBoost, XGBoost, and K-Nearest Neighbors. We use techniques such as pipeline construction and hyperparameter tuning with GridSearchCV to optimize the performance of these models.\n",
    "\n",
    "After training and evaluating individual models, we explore ensemble learning techniques such as Voting Classifier, which combines predictions from multiple base models to make a final prediction. We experiment with different combinations of base models to find the ensemble that yields the best performance in terms of accuracy and other evaluation metrics.\n",
    "\n",
    "Throughout the project, we focus on best practices in machine learning, including data preprocessing, model selection, hyperparameter tuning, and evaluation. The ultimate goal is to develop an accurate and reliable sentiment analysis model that can effectively analyze Twitter data and provide valuable insights into public opinion and sentiment trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "In today's digital age, companies and brands are increasingly leveraging social media platforms such as Twitter to connect with their audience, build brand loyalty, and monitor public sentiment. However, analyzing the vast amount of user-generated content on Twitter to gauge public opinion manually can be time-consuming and inefficient. Therefore, the business problem we aim to address with this project is the need for an automated sentiment analysis solution that accurately classifies tweets as either positive or negative. By automating the sentiment analysis process, companies can gain valuable insights into customer perceptions, identify emerging trends, and tailor their marketing strategies to better resonate with their target audience.\n",
    "\n",
    "The stakeholders who could benefit from this project include marketing professionals, brand managers, social media analysts, and business decision-makers. Marketing professionals can use the sentiment analysis tool to gauge the effectiveness of their marketing campaigns in real-time and adjust their strategies accordingly. Brand managers can monitor brand perception and identify potential issues or crises before they escalate. Social media analysts can track public sentiment trends over time and identify key influencers or opinion leaders within their industry. Business decision-makers can use the insights gained from sentiment analysis to make informed decisions about product development, customer service improvements, and crisis management strategies. Ultimately, this project aims to provide a valuable tool for stakeholders to better understand and respond to public sentiment on Twitter, thereby enhancing brand reputation and driving business success.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The dataset used in this project was sourced from [CrowdFlower](https://data.world/crowdflower/brands-and-product-emotions). It comprises tweets about various brands and products, with contributors tasked to evaluate whether each tweet expresses a positive, negative, or neutral emotion towards a specific brand or product. The dataset contains a total of 9093 rows of data. For each tweet, the target brand or product of the expressed emotion is identified. Exploratory analysis of the dataset reveals that it provides a rich source of information for sentiment analysis, as it captures real-time opinions and emotions expressed by users on Twitter regarding different brands and products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we embark on a journey to analyze sentiment in tweets related to Apple and Google products. Our goals are to understand the dataset's structure, clean and preprocess the data, and prepare it for a machine learning model that predicts sentiment based on tweet content. Let's start by loading the dataset and performing an exploratory data analysis (EDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Natural Language Toolkit for text processing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')  # Download NLTK resources if not already present\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Regular Expressions for pattern matching\n",
    "import re\n",
    "\n",
    "# String module for string operations\n",
    "import string\n",
    "\n",
    "# Counter for counting occurrences of elements\n",
    "from collections import Counter\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Evaluation Metrics and Visualization\n",
    "from sklearn.metrics import classification_report, accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Imbalanced-learn for dealing with class imbalance\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Other Utilities\n",
    "from itertools import combinations\n",
    "\n",
    "# Set up warning suppression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Explore the Dataset\n",
    "First, we load the dataset to understand its basic structure, including the number of entries, columns, and types of data it contains. This initial exploration is crucial for planning our preprocessing steps.\n",
    "\n",
    "The dataset contains three columns:\n",
    "- `tweet_text`: The text of the tweet.\n",
    "- `emotion_in_tweet_is_directed_at`: The product or brand the tweet is directed at (e.g., iPhone, iPad, Google).\n",
    "- `is_there_an_emotion_directed_at_a_brand_or_product`: The sentiment of the tweet (e.g., Positive emotion, Negative emotion).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9093, 3)\n",
      "Data types:\n",
      " tweet_text                                            object\n",
      "emotion_in_tweet_is_directed_at                       object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the CSV file containing the dataset\n",
    "data_path = 'data/judge-1377884607_tweet_product_company.csv'\n",
    "\n",
    "# Read the dataset into a pandas DataFrame using pd.read_csv()\n",
    "# We specify the encoding as 'ISO-8859-1' to handle potential encoding issues\n",
    "tweets_df = pd.read_csv(data_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Print the shape of the dataset (number of rows and columns)\n",
    "print(\"Dataset shape:\", tweets_df.shape)\n",
    "\n",
    "# Print the data types of each column in the dataset\n",
    "print(\"Data types:\\n\", tweets_df.dtypes)\n",
    "\n",
    "# Display the first few rows of the DataFrame using .head()\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values Analysis\n",
    "Identifying and handling missing values is crucial since they can significantly impact the performance of our model.\n",
    "\n",
    "The dataset contains missing values, primarily in the `emotion_in_tweet_is_directed_at` column, with a smaller number in the `tweet_text` column. Since our primary focus is sentiment analysis based on the tweet text, we'll proceed by dropping rows where the tweet text is missing. The `emotion_in_tweet_is_directed_at column` can be ignored for our current purpose, as we are focusing on sentiment, not the specific product mentioned.\n",
    "\n",
    "We will just drop the single row that is missing a tweet because this will not help our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column of the DataFrame using .isnull().sum()\n",
    "missing_values = tweets_df.isnull().sum()\n",
    "\n",
    "# Print the number of missing values in each column\n",
    "print(\"Missing values in each column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null values in the 'tweet_text' column in the original DataFrame\n",
    "tweets_df = tweets_df.dropna(subset=['tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution\n",
    "Understanding the balance between different sentiment classes helps us gauge the dataset's bias towards certain sentiments. This is important for selecting appropriate modeling and resampling techniques. \n",
    "\n",
    "The `is_there_an_emotion_directed_at_a_brand_or_product` column has four unique labels:\n",
    "\n",
    "- Negative emotion\n",
    "- Positive emotion\n",
    "- No emotion toward brand or product\n",
    "- I can't tell\n",
    "\n",
    "For the sentiment analysis model, we'll focus on positive and negative emotions. We'll treat \"No emotion toward brand or product\" and \"I can't tell\" as neutral or unknown sentiments, which might be excluded from the training to focus the model on distinguishing clearly between positive and negative sentiments.\n",
    "\n",
    "We have 2,978 positive and 570 negative sentiment tweets. This imbalance in the dataset could influence the performance of our model, making it potentially biased towards predicting positive sentiments. We'll need to keep this in mind during the modeling phase, possibly using techniques like oversampling the minority class, undersampling the majority class, or adjusting the class weights in the model training process to address this imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      " No emotion toward brand or product    5388\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_distribution = tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "print(\"Sentiment distribution:\\n\", sentiment_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Length Analysis\n",
    "Analyzing the length of tweets can reveal insights about the dataset's variability. To address the variability in text length observed in the dataset, we can leverage techniques such as text cleaning and TF-IDF (Term Frequency-Inverse Document Frequency) vectorization. Through text cleaning, we can remove punctuation, URLs, special characters, mentions, hashtags, and other non-essential elements from the tweets, resulting in a more standardized format. This process helps to ensure that the content of the tweets remains intact while eliminating unnecessary variations in text structure. Additionally, TF-IDF vectorization transforms each tweet into a fixed-length numerical vector representation based on the importance of each term relative to the entire dataset. This technique allows us to capture the significance of words in each tweet while normalizing the representation regardless of the absolute length of the tweet. \n",
    "\n",
    "These preprocessing steps are particularly useful given the insights gained from analyzing the text length distribution, where the mean length of tweets is approximately 105 characters with a standard deviation of around 27 characters. By employing these methods, we can effectively manage the variability in text length and facilitate consistent analysis across the dataset for tasks such as sentiment classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9092.000000\n",
       "mean      104.962275\n",
       "std        27.187640\n",
       "min        11.000000\n",
       "25%        86.000000\n",
       "50%       109.000000\n",
       "75%       126.000000\n",
       "max       178.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['text_length'] = tweets_df['tweet_text'].apply(lambda x: len(str(x)))\n",
    "tweets_df['text_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequent Words Analysis\n",
    "The frequent words analysis provides insights into the most commonly occurring words in the dataset, which can help us understand common themes and refine our list of stopwords. In the results provided, we observe that certain words such as **'#'**, **'sxsw'**, **'@'**, **'mention'**, **'.'**, **'the'**, **'link'**, **'}'**, **'{'**, **'to'**, **','**, **'at'**, **'rt'**, **';'**, **'&'**, **'google'**, **'for'**, **'ipad'**, **'!'**, and **'a'** appear frequently. However, many of these words are not informative in terms of sentiment analysis or topic classification. For example, symbols like **'#'**, **'@'**, **'.'**, **','**, **';'**, **'&'**, **'{'**, **'}'**, **'!'**, and **'rt'** are not indicative of sentiment and may be artifacts of social media platforms or text formatting. Similarly, common English stopwords like **'the'**, **'to'**, **'for'**, and **'a'** typically carry little sentiment value and can be safely removed to improve the accuracy of our models. Therefore, these frequent words will need to be removed from the text data before further analysis to focus on more meaningful terms that contribute to sentiment or topic identification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 15875),\n",
       " ('sxsw', 9516),\n",
       " ('@', 7194),\n",
       " ('mention', 7124),\n",
       " ('.', 5506),\n",
       " ('the', 4424),\n",
       " ('link', 4313),\n",
       " ('}', 4298),\n",
       " ('{', 4296),\n",
       " ('to', 3586),\n",
       " (',', 3533),\n",
       " ('at', 3102),\n",
       " ('rt', 2962),\n",
       " (';', 2800),\n",
       " ('&', 2707),\n",
       " ('google', 2595),\n",
       " ('for', 2545),\n",
       " ('ipad', 2446),\n",
       " ('!', 2398),\n",
       " ('a', 2312)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate all tweet texts into a single string, convert to lowercase\n",
    "all_words = ' '.join(tweets_df['tweet_text'].dropna()).lower()\n",
    "\n",
    "# Tokenize the concatenated string into individual words\n",
    "all_words_tokenized = word_tokenize(all_words)\n",
    "\n",
    "# Count the occurrences of each word and select the 20 most common words\n",
    "word_counts = Counter(all_words_tokenized)\n",
    "most_common_words = word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Characters and URLs Analysis\n",
    "Examining **special characters** and **URLs** in tweets is essential for preprocessing text data before sentiment analysis. **Special characters** such as hashtags (**'#'**), mentions (**'@'**), punctuation marks (**'.'**), and symbols (**'&'**, **'-'**, etc.) are often used in tweets for formatting, emphasis, or conveying information. While some of these characters may carry sentiment value (e.g., emojis), others are merely artifacts of social media communication and do not contribute meaningfully to sentiment analysis. Similarly, **URLs**, which often appear in tweets as hyperlinks to external content, typically do not convey sentiment on their own and may introduce noise into the analysis. Therefore, removing these **special characters** and **URLs** can help streamline the text preprocessing pipeline, reducing complexity and potentially improving model performance by focusing on the essential content of the tweets. Additionally, removing **URLs** can help mitigate privacy and security concerns associated with accessing external web resources during analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters counts: [('#', 15875), ('.', 8382), ('@', 7194), ('}', 4298), ('{', 4296), (',', 3558), (\"'\", 2903), (';', 2800), ('&', 2707), ('-', 2438)]\n",
      "Number of URLs: 44\n"
     ]
    }
   ],
   "source": [
    "# Extract special characters from each tweet using regular expressions\n",
    "special_chars = tweets_df['tweet_text'].apply(lambda x: re.findall(r'[^\\w\\s]', str(x)))\n",
    "\n",
    "# Count the occurrences of each special character\n",
    "special_chars_counts = Counter([item for sublist in special_chars for item in sublist])\n",
    "\n",
    "# Print the 10 most common special characters and their counts\n",
    "print(\"Special characters counts:\", special_chars_counts.most_common(10))\n",
    "\n",
    "# Count the number of URLs in the tweets using regular expressions\n",
    "urls_counts = tweets_df['tweet_text'].apply(lambda x: len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(x)))).sum()\n",
    "\n",
    "# Print the total number of URLs found in the tweets\n",
    "print(\"Number of URLs:\", urls_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Before Train/Test Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Sentiment Labels\n",
    "In the process of preparing our data for modeling, it's essential to convert the sentiment labels from their textual representation into a numerical format that our machine learning algorithms can understand. To achieve this, we utilize a mapping dictionary called sentiment_mapping, where we assign the value 1 to represent positive emotions and the value 0 to represent negative emotions. This encoding allows us to transform the sentiment labels from 'Positive emotion' and 'Negative emotion' to their corresponding numerical equivalents. By applying this mapping using the map() function to the column containing the sentiment labels in our DataFrame (tweets_df), we create a new column named sentiment_label, which now holds the encoded numerical values. This encoding step is crucial as it facilitates the subsequent modeling process, enabling our algorithms to effectively learn and make predictions based on the sentiment labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping dictionary to encode sentiment labels into numerical format\n",
    "sentiment_mapping = {\n",
    "    'Positive emotion': 1,  # Assign value 1 to represent positive emotion\n",
    "    'Negative emotion': 0   # Assign value 0 to represent negative emotion\n",
    "}\n",
    "\n",
    "# Map sentiment labels to their corresponding numerical values using the defined mapping\n",
    "# The 'is_there_an_emotion_directed_at_a_brand_or_product' column contains the sentiment labels\n",
    "# The result is stored in a new column named 'sentiment_label'\n",
    "tweets_df['sentiment_label'] = tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   tweet_text                                          9092 non-null   object \n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object \n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9092 non-null   object \n",
      " 3   text_length                                         9092 non-null   int64  \n",
      " 4   sentiment_label                                     3548 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 426.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "After encoding sentiment labels into numerical format, some rows in the dataset may still have missing sentiment labels due to unknown or no emotion expressed in the tweets. To ensure the integrity of our model training, it's essential to handle these missing values appropriately. In this case, we choose to remove rows with missing sentiment labels or cleaned tweets. By dropping these rows, we focus our analysis solely on tweets with clearly defined positive or negative emotions. This approach helps prevent potential misinterpretation of missing sentiment labels during model training, which could otherwise lead to biased or inaccurate predictions. Consequently, by retaining only the tweets with explicit sentiment labels, we streamline the dataset and enhance the quality of our sentiment analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3548 entries, 0 to 9088\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   tweet_text                                          3548 non-null   object \n",
      " 1   emotion_in_tweet_is_directed_at                     3191 non-null   object \n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  3548 non-null   object \n",
      " 3   text_length                                         3548 non-null   int64  \n",
      " 4   sentiment_label                                     3548 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 166.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with any missing sentiment labels or cleaned tweets\n",
    "tweets_df = tweets_df.dropna(subset=['sentiment_label'])\n",
    "tweets_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "Before training our model, we'll split the dataset into training and testing sets. This allows us to train our model on one subset of the data and then test its performance on unseen data, providing a better evaluation of its real-world performance. We will allocate 20% of the data for testing and 80% for training. The split maintains the distribution of sentiment labels to prevent bias. A random seed of 42 ensures reproducibility across runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tweets_df['tweet_text'],\n",
    "    tweets_df['sentiment_label'],\n",
    "    stratify=tweets_df['sentiment_label'],\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Text Data\n",
    "The next step in our preprocessing is to clean the text data. In this section, the text data undergoes preprocessing to ensure its suitability for sentiment analysis. The clean_tweet function is defined to perform several cleaning tasks. First, it converts all text to lowercase to standardize the case. Then, it removes punctuation, URLs, special characters, mentions, hashtags, and the term \"RT\" (typically used for retweets). Tokenization breaks the text into individual words, followed by the removal of stopwords and unnecessary whitespace. Lemmatization is applied to reduce words to their base forms. Finally, numeric characters are removed, and the cleaned tokens are rejoined into a string format. This cleaning process helps to eliminate noise and focus on the essential content of the tweets, enhancing the effectiveness of sentiment analysis. The cleaned text data is then applied to both the training and testing sets to prepare them for further processing and model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7003        someone buy ipad v1 wait line get v2 tomorrow\n",
       "8981    think effing hubby line ipad someone point tow...\n",
       "7351    smart company rumor apple opening temporary st...\n",
       "7483                   google map mobile look awesomesxsw\n",
       "1642        wishing excellent day today ive got ipad envy\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "def clean_tweet(tweet):\n",
    "   # Lowercase the text\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove special characters\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "        \n",
    "    # Remove the word link\n",
    "    tweet = re.sub(r'\\blink\\b', ' ', tweet)\n",
    "    \n",
    "     # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+\\b', ' ', tweet) \n",
    "    \n",
    "    # Remove the word mention\n",
    "    tweet = re.sub(r'\\bmention\\b', ' ', tweet)\n",
    "\n",
    "    # Remove sxsw\n",
    "    tweet = re.sub(r'\\bsxsw\\b', ' ', tweet)\n",
    "    \n",
    "     # Remove the word \"sxsw\" from concatenated words\n",
    "    tweet = re.sub(r'(?<=\\S)sxsw(?=\\S)', '', tweet)\n",
    "\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w+', ' ', tweet)\n",
    "    \n",
    "    # Remove \"RT\"\n",
    "    tweet = re.sub(r'\\brt\\b', ' ', tweet, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "     # Remove stopwords and unnecessary white spaces\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word.strip() for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Remove numeric characters\n",
    "    tokens = [word for word in tokens if not word.isdigit()]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    clean_tweet = ' '.join(tokens).strip()\n",
    "    \n",
    "    return clean_tweet\n",
    "\n",
    "\n",
    "X_train = X_train.apply(clean_tweet)\n",
    "X_test = X_test.apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters counts: []\n",
      "Number of URLs: 0\n"
     ]
    }
   ],
   "source": [
    "#Confirming all special characters and URLS are removed from the training set.\n",
    "special_chars = X_train.apply(lambda x: re.findall(r'[^\\w\\s]', str(x)))\n",
    "special_chars_counts = Counter([item for sublist in special_chars for item in sublist])\n",
    "print(\"Special characters counts:\", special_chars_counts.most_common(10))\n",
    "\n",
    "#URLs\n",
    "urls_counts = X_train.apply(lambda x: len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(x)))).sum()\n",
    "print(\"Number of URLs:\", urls_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters counts: []\n",
      "Number of URLs: 0\n"
     ]
    }
   ],
   "source": [
    "#Confirming all special characters and URLS are removed from the test set.\n",
    "special_chars = X_test.apply(lambda x: re.findall(r'[^\\w\\s]', str(x)))\n",
    "special_chars_counts = Counter([item for sublist in special_chars for item in sublist])\n",
    "print(\"Special characters counts:\", special_chars_counts.most_common(10))\n",
    "\n",
    "#URLs\n",
    "urls_counts = X_test.apply(lambda x: len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(x)))).sum()\n",
    "print(\"Number of URLs:\", urls_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipad', 941),\n",
       " ('apple', 775),\n",
       " ('google', 673),\n",
       " ('iphone', 531),\n",
       " ('store', 473),\n",
       " ('app', 361),\n",
       " ('new', 327),\n",
       " ('austin', 245),\n",
       " ('popup', 186),\n",
       " ('android', 181),\n",
       " ('ipad2', 178),\n",
       " ('launch', 159),\n",
       " ('get', 155),\n",
       " ('amp', 155),\n",
       " ('one', 138),\n",
       " ('time', 132),\n",
       " ('like', 129),\n",
       " ('line', 128),\n",
       " ('social', 125),\n",
       " ('circle', 120)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking most frequent words in the training set. This looks good.\n",
    "all_words = ' '.join(X_train.dropna()).lower()\n",
    "all_words_tokenized = word_tokenize(all_words)\n",
    "\n",
    "word_counts = Counter(all_words_tokenized)\n",
    "word_counts.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipad', 223),\n",
       " ('apple', 210),\n",
       " ('google', 159),\n",
       " ('iphone', 144),\n",
       " ('store', 121),\n",
       " ('app', 90),\n",
       " ('new', 75),\n",
       " ('austin', 71),\n",
       " ('get', 51),\n",
       " ('popup', 47),\n",
       " ('ipad2', 42),\n",
       " ('android', 41),\n",
       " ('amp', 40),\n",
       " ('launch', 36),\n",
       " ('day', 33),\n",
       " ('one', 33),\n",
       " ('line', 33),\n",
       " ('im', 32),\n",
       " ('party', 30),\n",
       " ('social', 29)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking most frequent words in the test set. This looks good.\n",
    "all_words = ' '.join(X_test.dropna()).lower()\n",
    "all_words_tokenized = word_tokenize(all_words)\n",
    "\n",
    "word_counts = Counter(all_words_tokenized)\n",
    "word_counts.most_common(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Vectorization (TF-IDF)\n",
    "In the text vectorization step, we convert the cleaned text data into a numerical format suitable for machine learning models using TF-IDF (Term Frequency-Inverse Document Frequency). TF-IDF reflects the importance of each word in a document relative to a collection of documents, allowing us to weigh terms accordingly. In the provided code, we first define a TF-IDF vectorizer with parameters for stopwords removal and maximum features to limit the dimensionality of the vectorized data. Next, we fit and transform the training data to create TF-IDF matrices, both for the training and test sets, ensuring consistency in data representation. Finally, we apply normalization to the TF-IDF matrices using 'l2' normalization to scale the data, which can improve model performance. Overall, this process enables us to represent text data numerically while preserving the inherent semantic information, facilitating effective sentiment analysis or classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TF-IDF vectorizer with stopwords removal and maximum features\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=10000)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf_un = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using the fitted TF-IDF vectorizer\n",
    "X_test_tfidf_un = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Normalize TF-IDF matrices\n",
    "tfidf_transformer = TfidfTransformer(norm='l2')  # 'l2' normalization\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_tfidf_un)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tfidf_un)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Class Imbalance\n",
    "To tackle the class imbalance observed in the sentiment labels, we employ random oversampling using the RandomOverSampler technique. This method involves randomly duplicating instances from the minority class (in this case, negative sentiment) to balance the class distribution. By increasing the representation of the minority class, we aim to prevent our model from becoming biased towards the majority class (positive sentiment), thereby improving its ability to generalize to unseen data and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4764, 5218),\n",
       " 0.0    2382\n",
       " 1.0    2382\n",
       " Name: sentiment_label, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "#Resample the training data\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Check the balance of the resampled data\n",
    "resampled_balance = pd.Series(y_train_resampled).value_counts()\n",
    "\n",
    "X_train_resampled.shape, resampled_balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "### Baseline Models\n",
    "In this code snippet, we're evaluating the performance of several machine learning models for sentiment analysis. The models include Multinomial Naive Bayes, Logistic Regression, Random Forest, AdaBoost, XGBoost, and K-Nearest Neighbors. These models are implemented using default settings, without any hyperparameter tuning, to provide a baseline assessment of their performance. The evaluation is conducted using cross-validation, splitting the training data into multiple subsets for training and validation. The results, displayed in a DataFrame, show the mean accuracy scores across different cross-validation folds for each model. While Random Forest demonstrates the highest mean accuracy (97.40%), it's noteworthy that there are indications of slight overfitting, particularly evident in models like Multinomial Naive Bayes and Logistic Regression. This overfitting was expected, given the class imbalance in the dataset, where oversampling was employed to mitigate bias towards the majority class. These results serve as a starting point for model selection and further optimization to improve generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Model  CV Train Mean  CV Test Mean  CV Test Std\n",
      "2            Random Forest         0.9988        0.9740       0.0040\n",
      "1      Logistic Regression         0.9837        0.9509       0.0076\n",
      "0  Multinomial Naive Bayes         0.9727        0.9215       0.0095\n",
      "4                  XGBoost         0.9622        0.8969       0.0058\n",
      "5      K-Nearest Neighbors         0.9102        0.8587       0.0139\n",
      "3                 AdaBoost         0.7803        0.7550       0.0061\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List to keep track of model performance\n",
    "model_performance = []\n",
    "\n",
    "# Function to evaluate a model and add its performance to our list\n",
    "def evaluate_model(model, model_name, X, y, cv=5):\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring='accuracy', return_train_score = True)\n",
    "    model_performance.append({\n",
    "        'Model': model_name,\n",
    "        'CV Train Mean': round(np.mean(scores['train_score']),4),\n",
    "        'CV Test Mean': round(np.mean(scores['test_score']),4),\n",
    "        'CV Test Std': round(np.std(scores['test_score']),4)\n",
    "    })\n",
    "\n",
    "\n",
    "# Define pipelines for different models\n",
    "nb_pipeline = Pipeline([('clf', MultinomialNB())])\n",
    "lr_pipeline = Pipeline([('clf', LogisticRegression(random_state=42))])\n",
    "rf_pipeline = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
    "ada_pipeline = Pipeline([('clf', AdaBoostClassifier(random_state=42))])\n",
    "xgb_pipeline = Pipeline([('clf', XGBClassifier(random_state=42))])\n",
    "knn_pipeline = Pipeline([('clf', KNeighborsClassifier())])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(nb_pipeline, 'Multinomial Naive Bayes', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(lr_pipeline, 'Logistic Regression', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(rf_pipeline, 'Random Forest', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(ada_pipeline, 'AdaBoost', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(xgb_pipeline, 'XGBoost', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(knn_pipeline, 'K-Nearest Neighbors', X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "# Convert the performance list to a DataFrame\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "\n",
    "# Sort the DataFrame by 'CV Test Accuracy Mean'\n",
    "sorted_performance_df = performance_df.sort_values(by='CV Test Mean', ascending=False)\n",
    "\n",
    "# Display the performance DataFrame\n",
    "print(sorted_performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV\n",
    "n the next step of our analysis, we will employ GridSearchCV to perform hyperparameter tuning for each of our machine learning models. GridSearchCV systematically searches through a predefined grid of hyperparameters and selects the combination that yields the best performance based on a specified evaluation metric. By tuning hyperparameters such as regularization strength, tree depth, and learning rate, we aim to optimize the models' performance and enhance their ability to generalize to unseen data. This process allows us to explore a wider range of model configurations and fine-tune them to achieve better accuracy and robustness in sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "After performing hyperparameter tuning using GridSearchCV for the Random Forest model, we obtained the best set of parameters as follows: 'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, and 'n_estimators': 500. The best mean cross-validated accuracy achieved with these parameters was approximately 98.66%. Subsequently, when evaluating the best model on the test set, we achieved an accuracy of around 89.58%.\n",
    "\n",
    "When comparing the results of the hyperparameter-tuned Random Forest model to the baseline models, we observe slight improvements in performance. The baseline Random Forest model had a cross-validated mean accuracy of approximately 97.40%, while the hyperparameter-tuned model achieved a higher cross-validated mean accuracy of approximately 98.66%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "Best Parameters: {'clf__criterion': 'entropy', 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__n_estimators': 500}\n",
      "Best Score: 0.9865665258758277\n",
      "Accuracy of Best Model: 0.895774647887324\n",
      "Classification Report of Best Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.40      0.55       114\n",
      "         1.0       0.90      0.99      0.94       596\n",
      "\n",
      "    accuracy                           0.90       710\n",
      "   macro avg       0.89      0.70      0.75       710\n",
      "weighted avg       0.89      0.90      0.88       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'clf__min_samples_split': [2, 5, 7, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'clf__criterion': ['gini', 'entropy']  # Example addition\n",
    "    }\n",
    "\n",
    "# Create a GridSearchCV object with the Random Forest pipeline and the parameter grid\n",
    "grid_search = GridSearchCV(rf_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = best_rf_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Accuracy of Best Model:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Classification Report of Best Model:\\n\", classification_report(y_test, y_pred_best))\n",
    "\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_rf_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Random Forest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "After conducting hyperparameter tuning using GridSearchCV for the Logistic Regression model, the best parameters were identified as 'C': 200, 'max_iter': 900, 'penalty': 'l1', and 'solver': 'saga'. With these parameters, the best mean cross-validated accuracy reached approximately 96.99%. Upon evaluating this tuned model on the test set, we achieved an accuracy of approximately 89.44%.\n",
    "\n",
    "Comparing these results to the baseline Logistic Regression model, which had a cross-validated mean accuracy of approximately 95.09%, we observe slight improvements in performance. The hyperparameter-tuned model demonstrates enhanced accuracy, suggesting that the fine-tuning of parameters has effectively optimized the model's predictive capabilities. Specifically, the precision, recall, and F1-score for both positive and negative classes have improved, indicating better classification performance overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters (Logistic Regression): {'clf__C': 200, 'clf__max_iter': 900, 'clf__penalty': 'l1', 'clf__solver': 'saga'}\n",
      "Best Score (Logistic Regression): 0.9699820116924001\n",
      "Accuracy of Best Model (Logistic Regression): 0.8943661971830986\n",
      "Classification Report of Best Model (Logistic Regression):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.54      0.62       114\n",
      "         1.0       0.92      0.96      0.94       596\n",
      "\n",
      "    accuracy                           0.89       710\n",
      "   macro avg       0.82      0.75      0.78       710\n",
      "weighted avg       0.89      0.89      0.89       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for Logistic Regression\n",
    "lr_param_grid = {\n",
    "'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 200, 300, 400],  # Regularization parameter\n",
    "    'clf__penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'clf__solver': ['liblinear', 'saga'],  # Optimization algorithm\n",
    "    'clf__max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Logistic Regression pipeline and the parameter grid\n",
    "lr_grid_search = GridSearchCV(lr_pipeline, lr_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "lr_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (Logistic Regression):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (Logistic Regression):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best Logistic Regression model\n",
    "y_pred_lr_best = best_lr_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best Logistic Regression model\n",
    "print(\"Accuracy of Best Model (Logistic Regression):\", accuracy_score(y_test, y_pred_lr_best))\n",
    "print(\"Classification Report of Best Model (Logistic Regression):\\n\", classification_report(y_test, y_pred_lr_best))\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_lr_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Logistic Regression)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes\n",
    "After conducting hyperparameter tuning using GridSearchCV for the Multinomial Naive Bayes model, the best parameters were identified as 'alpha': 0.1 and 'fit_prior': True. With these parameters, the best mean cross-validated accuracy reached approximately 94.21%. Upon evaluating this tuned model on the test set, we achieved an accuracy of approximately 86.34%.\n",
    "\n",
    "Comparing these results to the baseline Multinomial Naive Bayes model, which had a cross-validated mean accuracy of approximately 92.15%, we observe slight improvements in performance. The hyperparameter-tuned model demonstrates enhanced accuracy, suggesting that the fine-tuning of parameters has effectively optimized the model's predictive capabilities. Specifically, the precision, recall, and F1-score for both positive and negative classes have improved, indicating better classification performance overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best Parameters (Multinomial Naive Bayes): {'clf__alpha': 0.1, 'clf__fit_prior': True}\n",
      "Best Score (Multinomial Naive Bayes): 0.9420642023860962\n",
      "Accuracy of Best Model (Multinomial Naive Bayes): 0.8633802816901408\n",
      "Classification Report of Best Model (Multinomial Naive Bayes):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.64      0.60       114\n",
      "         1.0       0.93      0.91      0.92       596\n",
      "\n",
      "    accuracy                           0.86       710\n",
      "   macro avg       0.75      0.77      0.76       710\n",
      "weighted avg       0.87      0.86      0.87       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for Multinomial Naive Bayes\n",
    "nb_param_grid = {\n",
    "    'clf__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 1.0],  # Additive smoothing parameter\n",
    "    'clf__fit_prior': [True, False] # Whether to learn class prior probabilities\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Multinomial Naive Bayes pipeline and the parameter grid\n",
    "nb_grid_search = GridSearchCV(nb_pipeline, nb_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "nb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_nb_model = nb_grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (Multinomial Naive Bayes):\", nb_grid_search.best_params_)\n",
    "print(\"Best Score (Multinomial Naive Bayes):\", nb_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best Multinomial Naive Bayes model\n",
    "y_pred_nb_best = best_nb_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best Multinomial Naive Bayes model\n",
    "print(\"Accuracy of Best Model (Multinomial Naive Bayes):\", accuracy_score(y_test, y_pred_nb_best))\n",
    "print(\"Classification Report of Best Model (Multinomial Naive Bayes):\\n\", classification_report(y_test, y_pred_nb_best))\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(best_nb_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Naive Bayes)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "After conducting hyperparameter tuning using GridSearchCV for the XGBoost model, the optimal parameters were identified as 'learning_rate': 1.0, 'max_depth': 6, 'min_child_weight': 1, and 'n_estimators': 200. With these parameters, the best mean cross-validated accuracy achieved was approximately 95.00%. Subsequently, upon evaluating this tuned model on the test set, we obtained an accuracy of around 87.75%.\n",
    "\n",
    "Comparing these results to the baseline XGBoost model, which had a cross-validated mean accuracy of approximately 89.69%, we observe a slight decrease in performance. However, the hyperparameter-tuned model still demonstrates robust classification capabilities, with precision, recall, and F1-score values indicating strong performance for both positive and negative classes. Notably, the recall and F1-score for the negative class have slightly decreased, suggesting a slight reduction in the model's ability to correctly identify instances of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Best Parameters (XGBoost): {'clf__learning_rate': 1.0, 'clf__max_depth': 6, 'clf__min_child_weight': 1, 'clf__n_estimators': 200}\n",
      "Best Score (XGBoost): 0.9500429867644854\n",
      "Accuracy of Best Model (XGBoost): 0.8774647887323944\n",
      "Classification Report of Best Model (XGBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.54      0.59       114\n",
      "         1.0       0.92      0.94      0.93       596\n",
      "\n",
      "    accuracy                           0.88       710\n",
      "   macro avg       0.78      0.74      0.76       710\n",
      "weighted avg       0.87      0.88      0.87       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 150, 200],  # Number of boosting rounds\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],  # Step size shrinkage used in update\n",
    "    'clf__max_depth': [3, 4, 5, 6],  # Maximum depth of a tree\n",
    "    'clf__min_child_weight': [1, 2, 3]  # Minimum sum of instance weight (hessian) needed in a child\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the XGBoost pipeline and the parameter grid\n",
    "xgb_grid_search = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "xgb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb_model = xgb_grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (XGBoost):\", xgb_grid_search.best_params_)\n",
    "print(\"Best Score (XGBoost):\", xgb_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best XGBoost model\n",
    "y_pred_xgb_best = best_xgb_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best XGBoost model\n",
    "print(\"Accuracy of Best Model (XGBoost):\", accuracy_score(y_test, y_pred_xgb_best))\n",
    "print(\"Classification Report of Best Model (XGBoost):\\n\", classification_report(y_test, y_pred_xgb_best))\n",
    "\n",
    "# Plot confusion matrix for the best XGBoost model\n",
    "disp_xgb = ConfusionMatrixDisplay.from_estimator(best_xgb_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_xgb.ax_.set_title('Confusion Matrix (XGBoost)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "Following hyperparameter tuning with GridSearchCV for the K-Nearest Neighbors (KNN) model, the optimal parameters were determined to be 'algorithm': 'auto', 'n_neighbors': 3, and 'weights': 'distance'. These parameters led to the best mean cross-validated accuracy of approximately 91.90%. Subsequently, when evaluating the tuned KNN model on the test set, we achieved an accuracy of about 83.10%.\n",
    "\n",
    "In comparison to the baseline KNN model, which had a cross-validated mean accuracy of approximately 85.87%, the hyperparameter-tuned model demonstrates a slight improvement in performance. However, it's worth noting that the precision, recall, and F1-score values for both positive and negative classes are relatively consistent with the baseline model, suggesting that the hyperparameter tuning did not drastically alter the model's classification capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best Parameters (KNN): {'clf__algorithm': 'auto', 'clf__n_neighbors': 3, 'clf__weights': 'distance'}\n",
      "Best Score (KNN): 0.9189787667427936\n",
      "Accuracy of Best Model (KNN): 0.8309859154929577\n",
      "Classification Report of Best Model (KNN):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.59      0.53       114\n",
      "         1.0       0.92      0.88      0.90       596\n",
      "\n",
      "    accuracy                           0.83       710\n",
      "   macro avg       0.70      0.73      0.71       710\n",
      "weighted avg       0.85      0.83      0.84       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 9],  # Number of neighbors\n",
    "    'clf__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the KNN pipeline and the parameter grid\n",
    "knn_grid_search = GridSearchCV(knn_pipeline, knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "knn_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_knn_model = knn_grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (KNN):\", knn_grid_search.best_params_)\n",
    "print(\"Best Score (KNN):\", knn_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best KNN model\n",
    "y_pred_knn_best = best_knn_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best KNN model\n",
    "print(\"Accuracy of Best Model (KNN):\", accuracy_score(y_test, y_pred_knn_best))\n",
    "print(\"Classification Report of Best Model (KNN):\\n\", classification_report(y_test, y_pred_knn_best))\n",
    "\n",
    "# Plot confusion matrix for the best KNN model\n",
    "disp_knn = ConfusionMatrixDisplay.from_estimator(best_knn_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_knn.ax_.set_title('Confusion Matrix (KNN)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "After performing hyperparameter tuning using GridSearchCV for the AdaBoost model, the optimal parameters were determined to be 'algorithm': 'SAMME.R', 'learning_rate': 1.0, and 'n_estimators': 200. With these parameters, the best mean cross-validated accuracy achieved was approximately 87.72%. Subsequently, when evaluating this tuned model on the test set, we obtained an accuracy of approximately 82.54%.\n",
    "\n",
    "Comparing these results to the baseline AdaBoost model, which had a cross-validated mean accuracy of approximately 75.50%, we observe significant improvements in performance. The hyperparameter-tuned model demonstrates enhanced accuracy, precision, recall, and F1-score for both positive and negative classes, indicating improved classification performance overall. Specifically, the precision, recall, and F1-score for the negative class have notably increased, suggesting better identification of instances belonging to this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Best Parameters (AdaBoost): {'clf__algorithm': 'SAMME.R', 'clf__learning_rate': 1.0, 'clf__n_estimators': 200}\n",
      "Best Score (AdaBoost): 0.8772035676810074\n",
      "Accuracy of Best Model (AdaBoost): 0.8253521126760563\n",
      "Classification Report of Best Model (AdaBoost):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.54      0.50       114\n",
      "         1.0       0.91      0.88      0.89       596\n",
      "\n",
      "    accuracy                           0.83       710\n",
      "   macro avg       0.69      0.71      0.70       710\n",
      "weighted avg       0.84      0.83      0.83       710\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the parameter grid for AdaBoost\n",
    "ada_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 150, 200],  # Number of weak learners\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],  # Learning rate\n",
    "    'clf__algorithm': ['SAMME', 'SAMME.R']  # Algorithm for boosting\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the AdaBoost pipeline and the parameter grid\n",
    "ada_grid_search = GridSearchCV(ada_pipeline, ada_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "ada_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best model\n",
    "best_ada_model = ada_grid_search.best_estimator_\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (AdaBoost):\", ada_grid_search.best_params_)\n",
    "print(\"Best Score (AdaBoost):\", ada_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best AdaBoost model\n",
    "y_pred_ada_best = best_ada_model.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best AdaBoost model\n",
    "print(\"Accuracy of Best Model (AdaBoost):\", accuracy_score(y_test, y_pred_ada_best))\n",
    "print(\"Classification Report of Best Model (AdaBoost):\\n\", classification_report(y_test, y_pred_ada_best))\n",
    "\n",
    "# Plot confusion matrix for the best AdaBoost model\n",
    "disp_ada = ConfusionMatrixDisplay.from_estimator(best_ada_model, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_ada.ax_.set_title('Confusion Matrix (AdaBoost)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Modeling\n",
    "In this next section, we are implementing ensemble modeling techniques, specifically Hard and Soft Voting, to combine predictions from multiple individual models and make a collective decision. Ensemble modeling is beneficial as it leverages the diversity of multiple models to improve overall predictive performance and generalization.\n",
    "\n",
    "By examining both Hard and Soft Voting, we can explore different aggregation strategies and assess their effectiveness in improving the robustness and accuracy of the final prediction. Additionally, ensemble methods can help mitigate the limitations of individual models and enhance overall model stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hard Voting\n",
    "\n",
    "Hard voting is an ensemble technique where predictions from multiple individual models are combined by taking a majority vote. Each model provides its prediction for a given sample, and the final prediction is determined by the most common prediction among the individual models.\n",
    "\n",
    "In the provided code, we first define a list of estimators, each representing the best-performing model obtained through hyperparameter tuning for various algorithms such as Logistic Regression (lr), Naive Bayes (nb), Random Forest (rf), K-Nearest Neighbors (knn), AdaBoost (ada), and XGBoost (xgb). We then define a function, evaluate_combination, to evaluate combinations of these models using hard voting. The function creates a VotingClassifier with the specified combination of models, fits the ensemble model on the training data, makes predictions on the test data, and calculates accuracy along with a confusion matrix.\n",
    "\n",
    "The code proceeds to loop over all possible combinations of models, from single models to combinations of all models. For each combination, it evaluates the ensemble model's accuracy on the test data. The combination with the highest accuracy is then identified as the best combination. Finally, the best combination, its accuracy, and the corresponding confusion matrix are printed.\n",
    "\n",
    "In the results, the best combination of models for hard voting consists of Logistic Regression, Naive Bayes, and Random Forest. This combination achieved an accuracy of approximately 90.42% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination: ['lr', 'nb', 'rf']\n",
      "Best Accuracy: 0.9042253521126761\n",
      "Best Confusion Matrix:\n",
      " [[ 61  53]\n",
      " [ 15 581]]\n"
     ]
    }
   ],
   "source": [
    "# Define your estimators\n",
    "estimators = [('lr', best_lr_model), \n",
    "              ('nb', best_nb_model), \n",
    "              ('rf', best_rf_model), \n",
    "              ('knn', best_knn_model),\n",
    "              ('ada', best_ada_model),\n",
    "              ('xgb', best_xgb_model)]\n",
    "\n",
    "# Define a function to evaluate a combination of models\n",
    "def evaluate_combination(combination, X_train, y_train, X_test, y_test):\n",
    "    # Create the VotingClassifier with the specified combination\n",
    "    voting = VotingClassifier(estimators=combination, voting='hard')\n",
    "    \n",
    "    # Fit the ensemble model\n",
    "    voting.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = voting.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# Loop over all possible combinations of models\n",
    "best_accuracy = 0\n",
    "best_combination = None\n",
    "best_confusion_matrix = None\n",
    "\n",
    "for r in range(1, len(estimators) + 1):\n",
    "    for combination in combinations(estimators, r):\n",
    "        # Evaluate the combination using cross-validation\n",
    "        accuracy, cm = evaluate_combination(combination, X_train_resampled, y_train_resampled, X_test_tfidf, y_test)\n",
    "        \n",
    "        # Update best combination if accuracy is higher\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_combination = combination\n",
    "            best_confusion_matrix = cm\n",
    "\n",
    "# Print the best combination and its accuracy\n",
    "print(\"Best Combination:\", [estimator[0] for estimator in best_combination])\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Confusion Matrix:\\n\", best_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Voting\n",
    "Soft voting is another ensemble technique where predictions from multiple individual models are combined by averaging the predicted probabilities. In contrast to hard voting, soft voting takes into account the confidence level of each model's prediction rather than just the most common prediction.\n",
    "\n",
    "In the provided code, we define a list of estimators representing the best-performing models obtained through hyperparameter tuning for various algorithms. We then define a function, evaluate_combination, to evaluate combinations of these models using soft voting. The function creates a VotingClassifier with the specified combination of models, fits the ensemble model on the training data, makes predictions on the test data, calculates accuracy, and computes a confusion matrix.\n",
    "\n",
    "The code loops over all possible combinations of models, from single models to combinations of all models. For each combination, it evaluates the ensemble model's accuracy on the test data. The combination with the highest accuracy is identified as the best combination. Finally, the best combination, its accuracy, and the corresponding confusion matrix are printed.\n",
    "\n",
    "In the results, the best combination of models for soft voting consists of Naive Bayes, Random Forest, K-Nearest Neighbors, and XGBoost. This combination achieves an accuracy of approximately 90.14% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination: ['nb', 'rf', 'knn', 'xgb']\n",
      "Best Accuracy: 0.9014084507042254\n",
      "Best Confusion Matrix:\n",
      " [[ 59  55]\n",
      " [ 15 581]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your estimators\n",
    "estimators = [('lr', best_lr_model), \n",
    "              ('nb', best_nb_model), \n",
    "              ('rf', best_rf_model), \n",
    "              ('knn', best_knn_model),\n",
    "              ('ada', best_ada_model),\n",
    "              ('xgb', best_xgb_model)]\n",
    "\n",
    "# Define a function to evaluate a combination of models\n",
    "def evaluate_combination(combination, X_train, y_train, X_test, y_test):\n",
    "    # Create the VotingClassifier with the specified combination\n",
    "    voting = VotingClassifier(estimators=combination, voting='soft')\n",
    "    \n",
    "    # Fit the ensemble model\n",
    "    voting.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = voting.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# Loop over all possible combinations of models\n",
    "best_accuracy = 0\n",
    "best_combination = None\n",
    "best_confusion_matrix = None\n",
    "\n",
    "for r in range(1, len(estimators) + 1):\n",
    "    for combination in combinations(estimators, r):\n",
    "        # Evaluate the combination using cross-validation\n",
    "        accuracy, cm = evaluate_combination(combination, X_train_resampled, y_train_resampled, X_test_tfidf, y_test)\n",
    "        \n",
    "        # Update best combination if accuracy is higher\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_combination = combination\n",
    "            best_confusion_matrix = cm\n",
    "\n",
    "# Print the best combination and its accuracy\n",
    "print(\"Best Combination:\", [estimator[0] for estimator in best_combination])\n",
    "print(\"Best Accuracy:\", best_accuracy)\n",
    "print(\"Best Confusion Matrix:\\n\", best_confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Conclusion\n",
    "After evaluating the performance of various ensemble models, including individual classifiers such as Logistic Regression, Naive Bayes, Random Forest, K-Nearest Neighbors, AdaBoost, and XGBoost, the hard voting classifier emerged as the optimal choice. With an accuracy of approximately 90.42% on the holdout test data, the hard voting classifier demonstrates robust performance in sentiment analysis tasks. This implies its utility for real-world applications such as social media monitoring, brand reputation management, and customer sentiment analysis. By accurately classifying tweets into positive or negative sentiments, the hard voting classifier enables businesses to gain valuable insights into customer opinions, preferences, and satisfaction levels, allowing them to make informed decisions and tailor their marketing strategies accordingly. Therefore, the deployment of the hard voting classifier in sentiment analysis tasks holds significant implications for enhancing customer engagement, brand loyalty, and overall business performance in today's digital landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "- Source More Negative Sentiment Tweets: Given the class imbalance observed in the dataset, it's crucial to ensure adequate representation of negative sentiment tweets during training. Instead of relying solely on random oversampling, we should actively source more negative sentiment tweets from diverse sources or datasets. This approach will provide a more balanced training dataset, leading to better generalization and performance of the model, especially in accurately detecting negative sentiments.\n",
    "\n",
    "- Fine-Tuning Hyperparameters: Although we employed GridSearchCV to tune the hyperparameters of our models, there might still be room for further optimization. Experimenting with a broader range of hyperparameters or using more advanced optimization techniques like Bayesian optimization could help in finding better hyperparameter configurations that enhance the model's performance.\n",
    "\n",
    "- Feature Engineering: Explore additional features or text representations that could capture more nuanced information from the tweets. For instance, incorporating word embeddings like Word2Vec or GloVe could capture semantic relationships between words more effectively than traditional bag-of-words approaches. Additionally, extracting features such as sentiment lexicons, syntactic patterns, or contextual embeddings might provide valuable information to improve the model's understanding of tweet sentiment.\n",
    "\n",
    "By implementing these next steps, we can further enhance the performance and robustness of our sentiment analysis model, enabling more accurate and reliable predictions in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.858px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
