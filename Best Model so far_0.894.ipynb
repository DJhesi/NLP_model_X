{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter notebook, we embark on a journey to analyze sentiment in tweets related to Apple and Google products. Our goals are to understand the dataset's structure, clean and preprocess the data, and prepare it for a machine learning model that predicts sentiment based on tweet content. Let's start by loading the dataset and performing an exploratory data analysis (EDA).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary packages\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset\n",
    "First, we load the dataset to understand its basic structure, including the number of entries, columns, and types of data it contains. This initial exploration is crucial for planning our preprocessing steps.\n",
    "\n",
    "The dataset contains three columns:\n",
    "- `tweet_text`: The text of the tweet.\n",
    "- `emotion_in_tweet_is_directed_at`: The product or brand the tweet is directed at (e.g., iPhone, iPad, Google).\n",
    "- `is_there_an_emotion_directed_at_a_brand_or_product`: The sentiment of the tweet (e.g., Positive emotion, Negative emotion).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (9093, 3)\n",
      "Data types:\n",
      " tweet_text                                            object\n",
      "emotion_in_tweet_is_directed_at                       object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/judge-1377884607_tweet_product_company.csv'\n",
    "tweets_df = pd.read_csv(data_path, encoding='ISO-8859-1')\n",
    "print(\"Dataset shape:\", tweets_df.shape)\n",
    "print(\"Data types:\\n\", tweets_df.dtypes)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google maps for mobile 5.2 looks awesome.#sxsw'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['tweet_text'].iloc[7483]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google maps for mobile 5.2 looks awesome.#sxsw\n"
     ]
    }
   ],
   "source": [
    "original_tweet_7483 = tweets_df.loc[7483, 'tweet_text']\n",
    "print(original_tweet_7483)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Analysis\n",
    "Identifying and handling missing values is crucial since they can significantly impact the performance of our model.\n",
    "\n",
    "The dataset contains missing values, primarily in the `emotion_in_tweet_is_directed_at` column, with a smaller number in the `tweet_text` column. Since our primary focus is sentiment analysis based on the tweet text, we'll proceed by dropping rows where the tweet text is missing. The `emotion_in_tweet_is_directed_at column` can be ignored for our current purpose, as we are focusing on sentiment, not the specific product mentioned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " tweet_text                                               1\n",
      "emotion_in_tweet_is_directed_at                       5802\n",
      "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = tweets_df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with null values in the 'tweet_text' column in the original DataFrame\n",
    "tweets_df = tweets_df.dropna(subset=['tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Distribution\n",
    "Understanding the balance between different sentiment classes helps us gauge the dataset's bias towards certain sentiments. This is important for selecting appropriate modeling and resampling techniques. \n",
    "\n",
    "The `is_there_an_emotion_directed_at_a_brand_or_product` column has four unique labels:\n",
    "\n",
    "- Negative emotion\n",
    "- Positive emotion\n",
    "- No emotion toward brand or product\n",
    "- I can't tell\n",
    "\n",
    "For the sentiment analysis model, we'll focus on positive and negative emotions. We'll treat \"No emotion toward brand or product\" and \"I can't tell\" as neutral or unknown sentiments, which might be excluded from the training to focus the model on distinguishing clearly between positive and negative sentiments.\n",
    "\n",
    "We have 2,978 positive and 570 negative sentiment tweets. This imbalance in the dataset could influence the performance of our model, making it potentially biased towards predicting positive sentiments. We'll need to keep this in mind during the modeling phase, possibly using techniques like oversampling the minority class, undersampling the majority class, or adjusting the class weights in the model training process to address this imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment distribution:\n",
      " No emotion toward brand or product    5388\n",
      "Positive emotion                      2978\n",
      "Negative emotion                       570\n",
      "I can't tell                           156\n",
      "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_distribution = tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()\n",
    "print(\"Sentiment distribution:\\n\", sentiment_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Length Analysis\n",
    "Analyzing the length of tweets can reveal insights about the dataset's variability. It helps us decide if we need to normalize text lengths through padding or truncation during preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9092.000000\n",
       "mean      104.962275\n",
       "std        27.187640\n",
       "min        11.000000\n",
       "25%        86.000000\n",
       "50%       109.000000\n",
       "75%       126.000000\n",
       "max       178.000000\n",
       "Name: text_length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['text_length'] = tweets_df['tweet_text'].apply(lambda x: len(str(x)))\n",
    "tweets_df['text_length'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequent Words Analysis\n",
    "Identifying the most frequently occurring words will help us understand common themes and refine our list of stopwords. High-frequency words with little sentiment value might be removed to improve model accuracy.\n",
    "|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('#', 15875),\n",
       " ('sxsw', 9516),\n",
       " ('@', 7194),\n",
       " ('mention', 7124),\n",
       " ('.', 5506),\n",
       " ('the', 4424),\n",
       " ('link', 4313),\n",
       " ('}', 4298),\n",
       " ('{', 4296),\n",
       " ('to', 3586),\n",
       " (',', 3533),\n",
       " ('at', 3102),\n",
       " ('rt', 2962),\n",
       " (';', 2800),\n",
       " ('&', 2707),\n",
       " ('google', 2595),\n",
       " ('for', 2545),\n",
       " ('ipad', 2446),\n",
       " ('!', 2398),\n",
       " ('a', 2312)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "all_words = ' '.join(tweets_df['tweet_text'].dropna()).lower()\n",
    "all_words_tokenized = word_tokenize(all_words)\n",
    "\n",
    "word_counts = Counter(all_words_tokenized)\n",
    "word_counts.most_common(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#IPad2 's Û÷#SmartCoverÛª Opens to Instant Access - I should have waited to get one! - {link} #apple #SXSW\n",
      "1293\n"
     ]
    }
   ],
   "source": [
    "# Filter tweets containing 'link'\n",
    "link_tweets_df = tweets_df[tweets_df['tweet_text'].str.lower().str.contains('{link}', na=False)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(link_tweets_df['tweet_text'].iloc[1])\n",
    "\n",
    "print(len(link_tweets_df['tweet_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Characters and URLs Analysis\n",
    "Tweets often contain special characters, emojis, and URLs that may not contribute to sentiment analysis. Deciding whether to keep or remove these can impact preprocessing steps and ultimately model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special characters counts: [('#', 15875), ('.', 8382), ('@', 7194), ('}', 4298), ('{', 4296), (',', 3558), (\"'\", 2903), (';', 2800), ('&', 2707), ('-', 2438)]\n",
      "Number of URLs: 44\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "special_chars = tweets_df['tweet_text'].apply(lambda x: re.findall(r'[^\\w\\s]', str(x)))\n",
    "special_chars_counts = Counter([item for sublist in special_chars for item in sublist])\n",
    "print(\"Special characters counts:\", special_chars_counts.most_common(10))\n",
    "\n",
    "urls_counts = tweets_df['tweet_text'].apply(lambda x: len(re.findall(r\"http\\S+|www\\S+|https\\S+\", str(x)))).sum()\n",
    "print(\"Number of URLs:\", urls_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Sentiment Labels\n",
    "For our model to understand the sentiment labels, we need to encode them into a numerical format. In our case, we'll encode positive sentiment as 1 and negative sentiment as 0. This step is crucial for the subsequent modeling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_mapping = {\n",
    "    'Positive emotion': 1,\n",
    "    'Negative emotion': 0\n",
    "}\n",
    "\n",
    "# Update the mapping based on your dataset's sentiment labels\n",
    "tweets_df['sentiment_label'] = tweets_df['is_there_an_emotion_directed_at_a_brand_or_product'].map(sentiment_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9092 entries, 0 to 9092\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   tweet_text                                          9092 non-null   object \n",
      " 1   emotion_in_tweet_is_directed_at                     3291 non-null   object \n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  9092 non-null   object \n",
      " 3   text_length                                         9092 non-null   int64  \n",
      " 4   sentiment_label                                     3548 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 426.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n",
    "After cleaning the text, we need to address missing values. Missing sentiment labels or texts could mislead our model training. Depending on the context, we might choose to fill them with a placeholder value or remove those entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3548 entries, 0 to 9088\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   tweet_text                                          3548 non-null   object \n",
      " 1   emotion_in_tweet_is_directed_at                     3191 non-null   object \n",
      " 2   is_there_an_emotion_directed_at_a_brand_or_product  3548 non-null   object \n",
      " 3   text_length                                         3548 non-null   int64  \n",
      " 4   sentiment_label                                     3548 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 166.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping rows with any missing sentiment labels or cleaned tweets\n",
    "tweets_df = tweets_df.dropna(subset=['sentiment_label'])\n",
    "tweets_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data\n",
    "Before training our model, we'll split the dataset into training and testing sets. This allows us to train our model on one subset of the data and then test its performance on unseen data, providing a better evaluation of its real-world performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tweets_df['tweet_text'],\n",
    "    tweets_df['sentiment_label'],\n",
    "    stratify=tweets_df['sentiment_label'],\n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Text Data (BorA TTSplit?)\n",
    "The next step in our preprocessing is to clean the text data. This involves removing URLs, mentions, special characters, and numbers. These elements are generally not useful for sentiment analysis and can introduce noise into our model. Cleaning helps in focusing on the meaningful content of the tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7003        someone buy ipad v1 wait line get v2 tomorrow\n",
       "8981    think effing hubby line ipad someone point tow...\n",
       "7351    smart company rumor apple opening temporary st...\n",
       "7483                   google map mobile look awesomesxsw\n",
       "1642        wishing excellent day today ive got ipad envy\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "   # Lowercase the text\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    tweet = tweet.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "     # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+\\b', '', tweet) \n",
    "    \n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r'\\bmention\\b', '', tweet)\n",
    "\n",
    "    # Remove sxsw\n",
    "    tweet = re.sub(r'\\bsxsw\\b', '', tweet)\n",
    "\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    \n",
    "    # Remove \"RT\"\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(tweet)\n",
    "    \n",
    "     # Remove stopwords and unnecessary white spaces\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word.strip() for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization (optional)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Remove numeric characters\n",
    "    tokens = [word for word in tokens if not word.isdigit()]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    clean_tweet = ' '.join(tokens).strip()\n",
    "    \n",
    "    return clean_tweet\n",
    "X_train = X_train.apply(clean_tweet)\n",
    "X_test = X_test.apply(clean_tweet)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def clean_tweet(tweet):\n",
    "#     tweet = str(tweet).lower() #Lower case everything\n",
    "#     tweet = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', tweet, flags=re.MULTILINE)  # Remove URLs\n",
    "#     tweet = re.sub(r'\\@\\w+|\\#', '', tweet)  # Remove mentions and keep hashtags\n",
    "#     tweet = re.sub(r'\\d+', '', tweet)  # Remove numbers\n",
    "#     tweet = re.sub(r'[^\\w\\s]', '', tweet)  # Remove punctuation\n",
    "#     return tweet\n",
    "\n",
    "# # tweets_df['cleaned_tweet_text'] = tweets_df['tweet_text'].apply(clean_tweet)\n",
    "\n",
    "# X_train = X_train.apply(clean_tweet)\n",
    "# X_test = X_test.apply(clean_tweet)\n",
    "\n",
    "\n",
    "# # def preprocess_text(text):\n",
    "# #     # Tokenize text\n",
    "# #     tokens = word_tokenize(text)\n",
    "# #     # Remove punctuation\n",
    "# #     tokens = [token for token in tokens if token not in string.punctuation]\n",
    "# #     # Convert tokens to lowercase\n",
    "# #     tokens = [token.lower() for token in tokens]\n",
    "# #     # Lemmatize tokens\n",
    "# #     tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "# #     # Remove stop words\n",
    "# #     stop_words = set(stopwords.words('english'))\n",
    "# #     tokens = [token for token in tokens if token not in stop_words]\n",
    "# #     # Join tokens back into a single string\n",
    "# #     preprocessed_text = ' '.join(tokens)\n",
    "# #     return preprocessed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\johns\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('link', 1058),\n",
       " ('ipad', 941),\n",
       " ('apple', 775),\n",
       " ('google', 673),\n",
       " ('iphone', 531),\n",
       " ('store', 473),\n",
       " ('app', 361),\n",
       " ('new', 327),\n",
       " ('austin', 245),\n",
       " ('popup', 186),\n",
       " ('android', 181),\n",
       " ('ipad2', 178),\n",
       " ('launch', 159),\n",
       " ('get', 155),\n",
       " ('amp', 155),\n",
       " ('one', 138),\n",
       " ('time', 132),\n",
       " ('like', 129),\n",
       " ('line', 128),\n",
       " ('social', 125)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "all_words = ' '.join(X_train.dropna()).lower()\n",
    "all_words_tokenized = word_tokenize(all_words)\n",
    "\n",
    "word_counts = Counter(all_words_tokenized)\n",
    "word_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leminization (BorA TTSplit?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    "# # Lemmatization function\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# def lemmatize_text(text):\n",
    "#     return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "# # Apply cleaning and lemmatization\n",
    "# X_train = X_train.apply(lemmatize_text)\n",
    "# X_test = X_test.apply(lemmatize_text)\n",
    "\n",
    "# # Or \n",
    "\n",
    "# # tweets_df['cleaned_tweet_text'] = tweets_df['tweet_text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['google', 'map', 'mobile', 'look', 'awesomesxsw']\n"
     ]
    }
   ],
   "source": [
    "# Access the first tweet in the X_train Series\n",
    "first_tweet = X_train.iloc[3]\n",
    "\n",
    "# Split the tweet into tokens\n",
    "tokens = first_tweet.split()\n",
    "\n",
    "# Print the tokens\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Vectorization (TF-IDF) (BorA TTSplit?)\n",
    "Machine Learning models require numerical input, so we convert our cleaned text data into a numerical format using TF-IDF (Term Frequency-Inverse Document Frequency). This technique reflects how important a word is to a document in a collection, helping us to weigh the terms accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=10000)\n",
    "# X_tfidf = tfidf_vectorizer.fit_transform(tweets_df['cleaned_tweet_text'])\n",
    "\n",
    "# or\n",
    "# Vectorization with TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), max_features=10000, )\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance\n",
    "Our EDA revealed a class imbalance in the sentiment labels. To address this, we can use oversampling for the minority class to help in preventing our model from being biased towards the more frequent class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4764, 5200),\n",
       " 0.0    2382\n",
       " 1.0    2382\n",
       " Name: sentiment_label, dtype: int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "#Resample the training data\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Check the balance of the resampled data\n",
    "resampled_balance = pd.Series(y_train_resampled).value_counts()\n",
    "\n",
    "X_train_resampled.shape, resampled_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-5da48e8b50bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Multinomial Naive Bayes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Logistic Regression'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Random Forest'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mada_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AdaBoost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_pipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'XGBoost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-5da48e8b50bc>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model, model_name, X, y, cv)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Function to evaluate a model and add its performance to our list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     model_performance.append({\n\u001b[0;32m     16\u001b[0m         \u001b[1;34m'Model'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         indices = _generate_sample_indices(\n\u001b[0m\u001b[0;32m    173\u001b[0m             \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Assuming you've already defined your X (features) and y (target) from the cleaned data\n",
    "\n",
    "# List to keep track of model performance\n",
    "model_performance = []\n",
    "\n",
    "# Function to evaluate a model and add its performance to our list\n",
    "def evaluate_model(model, model_name, X, y, cv=5):\n",
    "    scores = cross_validate(model, X, y, cv=cv, scoring='accuracy', return_train_score = True)\n",
    "    model_performance.append({\n",
    "        'Model': model_name,\n",
    "        'CV Train Accuracy Mean': np.mean(scores['train_score']),\n",
    "        'CV Test Accuracy Mean': np.mean(scores['test_score']),\n",
    "        'CV Test Accuracy Std': np.std(scores['test_score'])\n",
    "    })\n",
    "\n",
    "# Example models to evaluate\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Define pipelines for different models\n",
    "nb_pipeline = Pipeline([('clf', MultinomialNB())])\n",
    "lr_pipeline = Pipeline([('clf', LogisticRegression(random_state=42))])\n",
    "rf_pipeline = Pipeline([('clf', RandomForestClassifier(random_state=42))])\n",
    "ada_pipeline = Pipeline([('clf', AdaBoostClassifier(random_state=42))])\n",
    "xgb_pipeline = Pipeline([('clf', XGBClassifier(random_state=42))])\n",
    "knn_pipeline = Pipeline([('clf', KNeighborsClassifier())])\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(nb_pipeline, 'Multinomial Naive Bayes', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(lr_pipeline, 'Logistic Regression', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(rf_pipeline, 'Random Forest', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(ada_pipeline, 'AdaBoost', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(xgb_pipeline, 'XGBoost', X_train_resampled, y_train_resampled)\n",
    "evaluate_model(knn_pipeline, 'K-Nearest Neighbors', X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "# Convert the performance list to a DataFrame\n",
    "performance_df = pd.DataFrame(model_performance)\n",
    "\n",
    "# Display the performance DataFrame\n",
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "nb_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = nb_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "lr_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = lr_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "rf_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = rf_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "ada_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = ada_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "xgb_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = xgb_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train the Random Forest pipeline on the entire training dataset\n",
    "knn_pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test set using the Random Forest pipeline\n",
    "y_pred_test = knn_pipeline.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'clf__min_samples_split': [2, 5, 7, 10],\n",
    "    'clf__min_samples_leaf': [1, 2, 3, 4, 5],\n",
    "    'clf__criterion': ['gini', 'entropy']  # Example addition\n",
    "    }\n",
    "\n",
    "# Create a GridSearchCV object with the Random Forest pipeline and the parameter grid\n",
    "grid_search = GridSearchCV(rf_pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Accuracy of Best Model:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Classification Report of Best Model:\\n\", classification_report(y_test, y_pred_best))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Random Forest)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the parameter grid for Logistic Regression\n",
    "lr_param_grid = {\n",
    "'clf__C': [0.001, 0.01, 0.1, 1, 10, 100, 200, 300, 400],  # Regularization parameter\n",
    "    'clf__penalty': ['l1', 'l2'],  # Regularization penalty\n",
    "    'clf__solver': ['liblinear', 'saga'],  # Optimization algorithm\n",
    "    'clf__max_iter': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1500, 2000]  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Logistic Regression pipeline and the parameter grid\n",
    "lr_grid_search = GridSearchCV(lr_pipeline, lr_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "lr_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (Logistic Regression):\", lr_grid_search.best_params_)\n",
    "print(\"Best Score (Logistic Regression):\", lr_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best Logistic Regression model\n",
    "y_pred_lr_best = lr_grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best Logistic Regression model\n",
    "print(\"Accuracy of Best Model (Logistic Regression):\", accuracy_score(y_test, y_pred_lr_best))\n",
    "print(\"Classification Report of Best Model (Logistic Regression):\\n\", classification_report(y_test, y_pred_lr_best))\n",
    "\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(lr_grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Logistic Regression)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Multinomial Naive Bayes\n",
    "nb_param_grid = {\n",
    "    'clf__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 1.0],  # Additive smoothing parameter\n",
    "    'clf__fit_prior': [True, False] # Whether to learn class prior probabilities\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the Multinomial Naive Bayes pipeline and the parameter grid\n",
    "nb_grid_search = GridSearchCV(nb_pipeline, nb_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "nb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (Multinomial Naive Bayes):\", nb_grid_search.best_params_)\n",
    "print(\"Best Score (Multinomial Naive Bayes):\", nb_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best Multinomial Naive Bayes model\n",
    "y_pred_nb_best = nb_grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best Multinomial Naive Bayes model\n",
    "print(\"Accuracy of Best Model (Multinomial Naive Bayes):\", accuracy_score(y_test, y_pred_nb_best))\n",
    "print(\"Classification Report of Best Model (Multinomial Naive Bayes):\\n\", classification_report(y_test, y_pred_nb_best))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best Logistic Regression model\n",
    "disp = ConfusionMatrixDisplay.from_estimator(nb_grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp.ax_.set_title('Confusion Matrix (Naive Bayes)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the parameter grid for AdaBoost\n",
    "ada_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 150, 200],  # Number of weak learners\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],  # Learning rate\n",
    "    'clf__algorithm': ['SAMME', 'SAMME.R']  # Algorithm for boosting\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the AdaBoost pipeline and the parameter grid\n",
    "ada_grid_search = GridSearchCV(ada_pipeline, ada_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "ada_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (AdaBoost):\", ada_grid_search.best_params_)\n",
    "print(\"Best Score (AdaBoost):\", ada_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best AdaBoost model\n",
    "y_pred_ada_best = ada_grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best AdaBoost model\n",
    "print(\"Accuracy of Best Model (AdaBoost):\", accuracy_score(y_test, y_pred_ada_best))\n",
    "print(\"Classification Report of Best Model (AdaBoost):\\n\", classification_report(y_test, y_pred_ada_best))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best AdaBoost model\n",
    "disp_ada = ConfusionMatrixDisplay.from_estimator(ada_grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_ada.ax_.set_title('Confusion Matrix (AdaBoost)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'clf__n_estimators': [50, 100, 150, 200],  # Number of boosting rounds\n",
    "    'clf__learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],  # Step size shrinkage used in update\n",
    "    'clf__max_depth': [3, 4, 5, 6],  # Maximum depth of a tree\n",
    "    'clf__min_child_weight': [1, 2, 3]  # Minimum sum of instance weight (hessian) needed in a child\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the XGBoost pipeline and the parameter grid\n",
    "xgb_grid_search = GridSearchCV(xgb_pipeline, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "xgb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (XGBoost):\", xgb_grid_search.best_params_)\n",
    "print(\"Best Score (XGBoost):\", xgb_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best XGBoost model\n",
    "y_pred_xgb_best = xgb_grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best XGBoost model\n",
    "print(\"Accuracy of Best Model (XGBoost):\", accuracy_score(y_test, y_pred_xgb_best))\n",
    "print(\"Classification Report of Best Model (XGBoost):\\n\", classification_report(y_test, y_pred_xgb_best))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best XGBoost model\n",
    "disp_xgb = ConfusionMatrixDisplay.from_estimator(xgb_grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_xgb.ax_.set_title('Confusion Matrix (XGBoost)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define the parameter grid for KNN\n",
    "knn_param_grid = {\n",
    "    'clf__n_neighbors': [3, 5, 7, 9],  # Number of neighbors\n",
    "    'clf__weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
    "    'clf__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute the nearest neighbors\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object with the KNN pipeline and the parameter grid\n",
    "knn_grid_search = GridSearchCV(knn_pipeline, knn_param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV to your data\n",
    "knn_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best Parameters (KNN):\", knn_grid_search.best_params_)\n",
    "print(\"Best Score (KNN):\", knn_grid_search.best_score_)\n",
    "\n",
    "# Predict using the best KNN model\n",
    "y_pred_knn_best = knn_grid_search.predict(X_test_tfidf)  # Make sure to transform your test set features as needed\n",
    "\n",
    "# Evaluate the best KNN model\n",
    "print(\"Accuracy of Best Model (KNN):\", accuracy_score(y_test, y_pred_knn_best))\n",
    "print(\"Classification Report of Best Model (KNN):\\n\", classification_report(y_test, y_pred_knn_best))\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot confusion matrix for the best KNN model\n",
    "disp_knn = ConfusionMatrixDisplay.from_estimator(knn_grid_search, X_test_tfidf, y_test, display_labels=['Negative', 'Positive'])\n",
    "disp_knn.ax_.set_title('Confusion Matrix (KNN)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a dictionary of emojis\n",
    "# emojis= {\n",
    "# '😒' : '[grumpy]',\n",
    "# '😡' : '[angry]',\n",
    "# '🤬' : '[cursing]',\n",
    "# '😞' : '[disappointed]',\n",
    "# '😤' : '[frustrated]',\n",
    "# '😭' : '[crying]',\n",
    "# '🤦‍♂️' : '[facepalmboy]',\n",
    "# '😑' : '[displeased]',\n",
    "# '😢' : '[tearful]',\n",
    "# '😱' : '[spooked]',\n",
    "# '😂' : '[laughing]',\n",
    "# '😄' : '[smiling]',\n",
    "# '😝' : '[silly]',\n",
    "# '🙄' : '[eyeroll]',\n",
    "# '😏' : '[smirking]',\n",
    "# '🤔' : '[confused]',\n",
    "# '🗳️' : '[voting]',\n",
    "# '📈' : '[stockup]',\n",
    "# '📉' : '[stockdown]',\n",
    "# '😩' : '[distressed]',\n",
    "# '😠' : '[mad]',\n",
    "# '😓' : '[unhappy]',\n",
    "# '🤣' : '[laughter]',\n",
    "# '😕' : '[uhoh]',\n",
    "# '🙅‍♂️' : '[crossarmsblue]',\n",
    "# '🤳' : '[arm]',\n",
    "# '🙅‍♀️' : '[crossarmspurple]',\n",
    "# '🔋' : '[battery]',\n",
    "# '😆' : '[bigsmile]',\n",
    "# '🤦‍♀️' : '[facepalmgirl]',\n",
    "# '📱' : '[phone]',\n",
    "# '😫' : '[distressed]',\n",
    "# '😅' : '[lmao]',\n",
    "# '🤨' : '[raisedeyebrow]',\n",
    "# '😔' : '[sad]',\n",
    "# '😖' : '[yikes]'\n",
    "# }\n",
    "\n",
    "# # Create a function to convert emojis to text\n",
    "# def emoji_fixer(x):\n",
    "#     for k in emojis.keys():\n",
    "#         x=x.replace(k, emojis[k])\n",
    "#     return x\n",
    "\n",
    "# # Apply the function to tweets column\n",
    "# neg_tweets['tweet']=neg_tweets['tweet'].apply(emoji_fixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.872px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
